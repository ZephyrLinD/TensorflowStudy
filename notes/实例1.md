## 通过上面的分析已经对tensorflow有了初步的认识，来看一个实例：
### 例：y = 0.1x + 0.2，构造线性模型并且训练，算出值
1. 我们需要用到tensorflow和numpy，所以
    ```
    import tensorflow as tf
    import numpy as np
    ```
2. 用numpy生成100个随机点
    ```
    x_data = np.random.rand(100)
    y_data = x_data * 0.1 + 0.2
    ```
    其中`y_data`为真实值<br>

3. 构造一个线性模型
    ```
    b = tf.Variable(0.)
    k = tf.Variable(0.)
    y = k * x_data + b  
    ```
4. 定义**二次代价函数**
    ```
    loss = tf.reduce_mean(tf.square(y_data - y))
    ```
    其中&nbsp;`y_data - y`&nbsp;是误差值（真实值减去测试值）<br>
    `tf.square`&nbsp;为误差的平方
    `tf.reduce_mean`&nbsp;为求出平均值
    所以**二次代价函数**就是求出**误差的平方的平均值**<br>

5. 定义一个**梯度下降法**来进行训练的优化器（Tensorflow已经封装好可以直接调用）
    ```
    optimizer = tf.train.GradientDescentOptimizer(0.2)
    ```
    其中`0.2`为学习率<br>

6. 最小化代价函数，最小化loss，越小越接近真实值
    ```
    train = optimizer.minimize(loss)
    ```
7. 最后一步，初始化变量，开始会话和迭代，我们设置每迭代20次输出一次值
    ```
    init = tf.global_variables_initializer()

    with tf.Session() as sess:
    sess.run(init)
    for step in range(201):
        sess.run(train)
        if step % 20 == 0:
            print(step, sess.run([k, b]))
    ```
### 训练结果十分接近真实值：
```
0 [0.05784461, 0.10135051]
20 [0.10611775, 0.19648236]
40 [0.10341891, 0.1980342]
60 [0.10191065, 0.19890141]
80 [0.10106779, 0.19938605]
100 [0.10059675, 0.19965689]
120 [0.10033349, 0.19980825]
140 [0.10018638, 0.19989283]
160 [0.10010417, 0.19994012]
180 [0.10005819, 0.19996653]
200 [0.10003253, 0.19998129]
```